---
categories:
- ""
- ""
date: "2017-10-31T22:26:09-05:00"
draft: false
image: climate.jpg
keywords: ""
slug: Climate Change
title: Climate Change
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="climate-change-and-temperature-anomalies" class="section level1">
<h1>Climate change and temperature anomalies</h1>
<p>A key metric in climate change is the <em>Combined Land-Surface Air and Sea-Surface Water Temperature Anomalies</em> in the Northern Hemisphere at <a href="https://data.giss.nasa.gov/gistemp">NASA’s Goddard Institute for Space Studies</a>.</p>
<p>We will analyze the change in climate change by looking at temperatures today compared to NASA’s base period between 1951-1980.</p>
<p>First we load the climate change date which gives us the deviation of the temperature in each month compared to the base period.</p>
<pre class="r"><code>weather &lt;- 
  read_csv(&quot;https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv&quot;, 
           skip = 1, 
           na = &quot;***&quot;)</code></pre>
<p>Going forward we will work with the months only and not combined periods. We therefore setup a code that only incldudes the monthly data and year.</p>
<p>We then convert the dataframe to a long format. This is usefull because it will later on let us plot the data more easily.</p>
<ol style="list-style-type: decimal">
<li>Convert the dataframe from wide to ‘long’ format. Hint: use <code>gather()</code> or <code>pivot_longer()</code> function. Name the new dataframe as <code>tidyweather</code>, name the variable containing the name of the month as <code>month</code>, and the temperature deviation values as <code>delta</code>.</li>
</ol>
<pre class="r"><code>#Select the weather dataframe

tidyweather&lt;-weather %&gt;% 
  
  #Select the year and the twelve month variables from the `weather` dataset
  select(Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec) %&gt;%

  #Converting the dataframe to a longer format with the names from months and values from the delta. 
  pivot_longer(cols =2:13,
               names_to=&quot;Month&quot;,
               values_to=&quot;delta&quot;) 
  
  
#Print the dataframe.
tidyweather</code></pre>
<pre><code>## # A tibble: 1,704 x 3
##     Year Month delta
##    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
##  1  1880 Jan   -0.35
##  2  1880 Feb   -0.51
##  3  1880 Mar   -0.23
##  4  1880 Apr   -0.3 
##  5  1880 May   -0.06
##  6  1880 Jun   -0.16
##  7  1880 Jul   -0.18
##  8  1880 Aug   -0.26
##  9  1880 Sep   -0.23
## 10  1880 Oct   -0.32
## # ... with 1,694 more rows</code></pre>
<p>Our dataframe now only has three columns which shows the year, month, and delta. The number of rows has increased from 142 to 1,704 (12x) because we have expanded the months to be on the rows instead of columns.</p>
<div id="plotting-climate-change" class="section level2">
<h2>Plotting Climate Change</h2>
<p>We will now plot the data on a time-series scatter plot. We will further add a trendline to see the development over time. To do that, we first need to create a new variable called <code>date</code> in order to ensure that the <code>delta</code> values are plot chronologically.</p>
<pre class="r"><code>#Adding a date row
tidyweather &lt;- tidyweather %&gt;%
  mutate(date = ymd(paste(as.character(Year), Month, &quot;1&quot;)))


#Plotting date versus delta (difference compared to expectations)
ggplot(tidyweather, aes(x=date, y = delta))+
  
  #Scatterplot
  geom_point()+
  
  #Trendline in red without Standard error
  geom_smooth(color=&quot;red&quot;, se=F) +
  
  #Minimal theme
  theme_bw() +
  
  #Titles
  labs (
    title = &quot;Weather Anomalies over time&quot;,
    subtitle = &quot;Temperatures compared to the expected temperatures for NASA&#39;s base periods (1950-1980)&quot;,
    x = &quot;Year&quot;,
    y = &quot;Degrees difference to NASA&#39;s base period&quot;) + 
  
  #Setting breaks smaller to see more accurately the changes
  scale_y_continuous(breaks = (seq(-2, 2,0.5))) + 
  NULL</code></pre>
<p><img src="/blogs2/blog2_files/figure-html/scatter_plot-1.png" width="648" style="display: block; margin: auto;" />
The plot shows that over time temperatures have rised compared to NASA’s base period. This result is expected given the global warming effect which is steadily increasing.</p>
<p>We would like to analyze if this effect is more pronounced in some months than other. To do this we use the same data but facet wrap by month.</p>
<p><img src="/blogs2/blog2_files/figure-html/facet_wrap-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>This plot is interesting as it shows some months such as Nov, Dec Jan, Feb and Mar have experienced higher increases compared to other months. Since those months are generally colder and they are more exposed to the impact of global warming. I.e. global warming leads to warmer winters more so than warmer summers.</p>
<p>We now set up a comparison of different time periods to see how this has changed over time.</p>
<pre class="r"><code>comparison &lt;- tidyweather %&gt;% 
  filter(Year&gt;= 1881) %&gt;%     #remove years prior to 1881
  #create new variable &#39;interval&#39;, and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ &quot;1881-1920&quot;,
    Year %in% c(1921:1950) ~ &quot;1921-1950&quot;,
    Year %in% c(1951:1980) ~ &quot;1951-1980&quot;,
    Year %in% c(1981:2010) ~ &quot;1981-2010&quot;,
    TRUE ~ &quot;2011-present&quot;
  ))

#To print the table
comparison</code></pre>
<pre><code>## # A tibble: 1,692 x 5
##     Year Month delta date       interval 
##    &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;    
##  1  1881 Jan   -0.3  1881-01-01 1881-1920
##  2  1881 Feb   -0.21 1881-02-01 1881-1920
##  3  1881 Mar   -0.03 1881-03-01 1881-1920
##  4  1881 Apr    0.01 1881-04-01 1881-1920
##  5  1881 May    0.04 1881-05-01 1881-1920
##  6  1881 Jun   -0.32 1881-06-01 1881-1920
##  7  1881 Jul    0.08 1881-07-01 1881-1920
##  8  1881 Aug   -0.04 1881-08-01 1881-1920
##  9  1881 Sep   -0.26 1881-09-01 1881-1920
## 10  1881 Oct   -0.43 1881-10-01 1881-1920
## # ... with 1,682 more rows</code></pre>
<p>This data now shows the interval of time which can be useful for plotting the data by interval.</p>
<pre class="r"><code>#Comparing delta to time interval
ggplot(comparison, aes(x=delta, fill=interval))+
  
  #density plot with tranparency set to 20%
  geom_density(alpha=0.2) +   
  
  #theme
  theme_bw() +              
  labs (
    title = &quot;Density Plot for Monthly Temperature Anomalies&quot;,
    y     = &quot;Density&quot;,         #changing y-axis label to sentence case, 
    x = &quot;Delta from base periods&quot;
  ) + 
  
  #Setting breaks smaller to see more accurately the changes
  scale_y_continuous(breaks = (seq(0, 2,0.5))) + 
  NULL</code></pre>
<p><img src="/blogs2/blog2_files/figure-html/density_plot-1.png" width="648" style="display: block; margin: auto;" />
What we see is that each interval slowly moves toward the right as time progresses with the current interval being much higher than the remaining. The green interval is the base period and is naturally centered around 0.</p>
<p>We now proceed to look into annual anomalies instead of monthly anomalies to see if this makes any difference in our conclusions.</p>
<pre class="r"><code>#creating yearly averages
average_annual_anomaly &lt;- tidyweather %&gt;% 
  
  #grouping data by Year
  group_by(Year) %&gt;%   
  
  # use `na.rm=TRUE` to eliminate NA (not available) values 
  summarise(annual_average_delta=mean(delta, na.rm=TRUE))

#plotting the data:
ggplot(average_annual_anomaly, aes(x=Year, y= annual_average_delta))+
  geom_point()+
  
  #Fit the best fit line, using LOESS method
  geom_smooth(method=&quot;loess&quot;) +
  
  #change to theme_bw() to have white background + black frame around plot
  theme_bw() +
  labs (
    title = &quot;Average Yearly Anomaly&quot;,
    y     = &quot;Average Annual Delta&quot;
  )                         </code></pre>
<p><img src="/blogs2/blog2_files/figure-html/averaging-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Not surprisingly we see a similar result from the yearly averages compared to the monthly averages.</p>
</div>
<div id="confidence-interval-for-delta" class="section level2">
<h2>Confidence Interval for <code>delta</code></h2>
<p><a href="https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php">NASA points out on their website</a> that</p>
<blockquote>
<p>A one-degree global change is significant because it takes a vast amount of heat to warm all the oceans, atmosphere, and land by that much. In the past, a one- to two-degree drop was all it took to plunge the Earth into the Little Ice Age.</p>
</blockquote>
<p>We therefore find it interesting to look into the confidence interval of delta since 2011 to determine how close we are to the 2-degree change. We first look into this by using a formula approach to extrapolate the confidence interval</p>
<pre class="r"><code>formula_ci &lt;- comparison %&gt;% 
  
  #Filtering for the relevant intervalt
  filter(interval==&quot;2011-present&quot;) %&gt;% 
  
  # calculate summary statistics for temperature deviation (delta) 
  summarise(annual_average_delta=mean(delta,na.rm=TRUE),
            sd_delta=sd(delta,na.rm=TRUE),
            count= n(),
            t_critical = qt(0.975,count-1),
            se_delta=sd_delta/sqrt(count),
            margin_of_error= t_critical*se_delta,
            delta_low= annual_average_delta - margin_of_error,
            delta_high= annual_average_delta + margin_of_error) %&gt;%   # calculate mean, SD, count, SE, lower/upper 95% CI
  arrange(desc(annual_average_delta)) # do we need this?

formula_ci #print out formula_CI</code></pre>
<pre><code>## # A tibble: 1 x 8
##   annual_average_delta sd_delta count t_critical se_delta margin_of_error delta_low
##                  &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;     &lt;dbl&gt;
## 1                 1.06    0.274   132       1.98   0.0239          0.0472      1.01
## # ... with 1 more variable: delta_high &lt;dbl&gt;</code></pre>
<p>What we see is that our annual average delta since 2011 is 1.06 with a 95% confidence interval from 1.01 to 1.11. Stated in otherwords our 95% confidence interval reflects an increase in temperature of 1.01 to 1.11 degrees for the years 2011-present.</p>
<p>We can use bootstrap method to see if we still maintain similar results.</p>
<pre class="r"><code># use the infer package to construct a 95% CI for delta


set.seed(1234)

boot_delta &lt;- comparison %&gt;%
  # choose the interval 2011-present
  filter(interval==&quot;2011-present&quot;) %&gt;% # choose the interval 2011-present
  
  # Specify the variable of interest
  specify(response = delta) %&gt;%
  
  # Generate a bunch of bootstrap samples
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;%
  
  # Find the median of each sample
  calculate(stat = &quot;mean&quot;)

#Finding the confidence intervals
percentile_ci&lt;-boot_delta %&gt;% 
  get_confidence_interval(level=0.95,type=&quot;percentile&quot;)

#Printing the results
percentile_ci</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     1.01     1.11</code></pre>
<p>We are achieving very similar results with a confidence interval of 1.02 to 1.11 degrees above NASA’s reference period.</p>
<p>In sum, our analysis on temperature increases shows that temperatures have been steadily rising for the past 100 years. In addition, the winter months have seen the largest increases in temperature. Furthermore the most recent decade is the warmest decade we have recorded to date. We know that a 2-degree change in temperature can drastically impact the climate. Our statistics shows that we are 95% confident the average current rise in temperatures is 1.01-1.11 higher than the reference period only 41 years after it ended in 1981.</p>
</div>
</div>
<div id="global-warming-and-political-views-gss" class="section level1">
<h1>Global warming and political views (GSS)</h1>
<p>It is interesting to now see how global warming relates to political views in the general public.</p>
<p><a href="https://www.pewresearch.org/2010/10/27/wide-partisan-divide-over-global-warming/">A 2010 Pew Research poll</a> asked 1,306 Americans, “From what you’ve read and heard, is there solid evidence that the average temperature on earth has been getting warmer over the past few decades, or not?”</p>
<p>We will now analyze if there is a difference between the proportion of people who believe the world is getting warmer and their political ideology.</p>
<p>We load the dataset first.</p>
<pre class="r"><code>global_warming_pew &lt;- read_csv(here::here(&quot;data&quot;, &quot;global_warming_pew.csv&quot;))</code></pre>
<p>We will first count the number of votes to get a summary of the data.</p>
<pre class="r"><code>warming_long &lt;- global_warming_pew %&gt;% 
  count(party_or_ideology, response)

warming_long</code></pre>
<pre><code>## # A tibble: 12 x 3
##    party_or_ideology       response                          n
##    &lt;chr&gt;                   &lt;chr&gt;                         &lt;int&gt;
##  1 Conservative Republican Don&#39;t know / refuse to answer    45
##  2 Conservative Republican Earth is warming                248
##  3 Conservative Republican Not warming                     450
##  4 Liberal Democrat        Don&#39;t know / refuse to answer    23
##  5 Liberal Democrat        Earth is warming                405
##  6 Liberal Democrat        Not warming                      23
##  7 Mod/Cons Democrat       Don&#39;t know / refuse to answer    45
##  8 Mod/Cons Democrat       Earth is warming                563
##  9 Mod/Cons Democrat       Not warming                     158
## 10 Mod/Lib Republican      Don&#39;t know / refuse to answer    23
## 11 Mod/Lib Republican      Earth is warming                135
## 12 Mod/Lib Republican      Not warming                     135</code></pre>
<p>We notice that some people have not responded which we will therefore filter out.</p>
<p>We will also be constructing three 95% confidence intervals to estimate population parameters, for the % who believe that <strong>Earth is warming</strong>, according to their party or ideology.</p>
<pre class="r"><code>warming_wide &lt;- warming_long %&gt;% 
  
  #Taking out those who didn&#39;t answer
  subset(response!=&quot;Don&#39;t know / refuse to answer&quot;) %&gt;% 
  
  #Widening the chart to make it easier to work with
  pivot_wider(names_from=response,
              values_from=n) %&gt;% 
  
  #Renaming columns to make them easier to work with
  rename(&quot;Yes&quot;=&quot;Earth is warming&quot;,&quot;No&quot;=&quot;Not warming&quot;) %&gt;%
  
  #manually creating CIs
  mutate(
    Total=Yes+No,
    Pr_Yes=Yes/Total,
    t_critical = qt(0.975, Total-1),
    SE=sqrt((Pr_Yes*(1-Pr_Yes))/Total),
    Lower95=Pr_Yes-t_critical*SE,
    Upper95=Pr_Yes+t_critical*SE,
  )
warming_wide</code></pre>
<pre><code>## # A tibble: 4 x 9
##   party_or_ideology     Yes    No Total Pr_Yes t_critical     SE Lower95 Upper95
##   &lt;chr&gt;               &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 Conservative Repub~   248   450   698  0.355       1.96 0.0181   0.320   0.391
## 2 Liberal Democrat      405    23   428  0.946       1.97 0.0109   0.925   0.968
## 3 Mod/Cons Democrat     563   158   721  0.781       1.96 0.0154   0.751   0.811
## 4 Mod/Lib Republican    135   135   270  0.5         1.97 0.0304   0.440   0.560</code></pre>
<pre class="r"><code>#This can also be visualized, reordering by highest percentage who believes 
ggplot(warming_wide, aes(x=reorder(party_or_ideology, Pr_Yes), y=Pr_Yes, colour=party_or_ideology)) +
  geom_point() +
  
  #Errorbar to show CI
  geom_errorbar(width=.5, aes(ymin=Lower95, ymax=Upper95)) + 
  
  labs(x=&quot; &quot;,
       y= &quot;Percentage of people believing the earth is warming&quot;, 
       title=&quot;Which party or ideology has the most % believe that Earth is warming?&quot;) + 
  theme_bw()+
  
  #Flipping coordinates
  coord_flip()+
  
  #Removing legend
  theme(legend.position = &quot;none&quot;)+
  NULL</code></pre>
<p><img src="/blogs2/blog2_files/figure-html/unnamed-chunk-2-1.png" width="648" style="display: block; margin: auto;" />
It appears respondants beliefs on global warming are very heavily dependent on their political party.</p>
</div>
<div id="bidens-approval-margins" class="section level1">
<h1>Biden’s Approval Margins</h1>
<p>We now want to look into Biden’s approval margins</p>
<pre class="r"><code># Import approval polls data directly off fivethirtyeight website
approval_polllist &lt;- read_csv(&#39;https://projects.fivethirtyeight.com/biden-approval-data/approval_polllist.csv&#39;) 

glimpse(approval_polllist)</code></pre>
<pre><code>## Rows: 1,908
## Columns: 22
## $ president           &lt;chr&gt; &quot;Joseph R. Biden Jr.&quot;, &quot;Joseph R. Biden Jr.&quot;, &quot;Jos~
## $ subgroup            &lt;chr&gt; &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;~
## $ modeldate           &lt;chr&gt; &quot;10/14/2021&quot;, &quot;10/14/2021&quot;, &quot;10/14/2021&quot;, &quot;10/14/2~
## $ startdate           &lt;chr&gt; &quot;1/19/2021&quot;, &quot;1/19/2021&quot;, &quot;1/20/2021&quot;, &quot;1/20/2021&quot;~
## $ enddate             &lt;chr&gt; &quot;1/21/2021&quot;, &quot;1/21/2021&quot;, &quot;1/21/2021&quot;, &quot;1/21/2021&quot;~
## $ pollster            &lt;chr&gt; &quot;Morning Consult&quot;, &quot;Rasmussen Reports/Pulse Opinio~
## $ grade               &lt;chr&gt; &quot;B&quot;, &quot;B&quot;, &quot;B+&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B+&quot;, &quot;B&quot;, &quot;B~
## $ samplesize          &lt;dbl&gt; 15000, 1500, 1516, 1115, 1993, 15000, 15000, 941, ~
## $ population          &lt;chr&gt; &quot;a&quot;, &quot;lv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;lv&quot;, &quot;~
## $ weight              &lt;dbl&gt; 0.2594, 0.3382, 1.2454, 1.1014, 0.0930, 0.2333, 0.~
## $ influence           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ approve             &lt;dbl&gt; 50, 48, 45, 55, 56, 51, 52, 63, 48, 58, 48, 55, 53~
## $ disapprove          &lt;dbl&gt; 28.0, 45.0, 28.0, 32.0, 31.0, 28.0, 29.0, 37.0, 47~
## $ adjusted_approve    &lt;dbl&gt; 48.6, 50.5, 46.5, 53.9, 54.6, 49.6, 50.6, 58.7, 50~
## $ adjusted_disapprove &lt;dbl&gt; 31.3, 38.8, 28.4, 33.0, 34.3, 31.3, 32.3, 38.0, 40~
## $ multiversions       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA~
## $ tracking            &lt;lgl&gt; TRUE, TRUE, NA, NA, NA, TRUE, TRUE, NA, TRUE, NA, ~
## $ url                 &lt;chr&gt; &quot;https://morningconsult.com/form/global-leader-app~
## $ poll_id             &lt;dbl&gt; 74272, 74247, 74327, 74248, 74246, 74273, 74274, 7~
## $ question_id         &lt;dbl&gt; 139491, 139395, 139570, 139404, 139394, 139492, 13~
## $ createddate         &lt;chr&gt; &quot;1/28/2021&quot;, &quot;1/22/2021&quot;, &quot;2/2/2021&quot;, &quot;1/22/2021&quot;,~
## $ timestamp           &lt;chr&gt; &quot;09:26:10 14 Oct 2021&quot;, &quot;09:26:10 14 Oct 2021&quot;, &quot;0~</code></pre>
<p>We glimpse to understand the data and see an array of factors most importantly the approve and disapprove.</p>
<p><img src="C:/Users/karim/Desktop/Git/my_website/images/biden_approval_margin.png" width="100%" style="display: block; margin: auto;" /></p>
<div id="create-a-plot" class="section level2">
<h2>Create a plot</h2>
<p>We will now calculate the new approval rate (approve- disapprove) for each week since he got into office. We will plot this along with its 95% confidence interval. ´</p>
<p>We will setup a graph similar to the one below:</p>
<p>We plot this with the following code:</p>
<pre class="r"><code>#calculate the average net approval rate for each week
net_approval_polllist &lt;- approval_polllist %&gt;% 
  
  #Subgroubing by all polls to avoid overlap
  filter(subgroup == &quot;All polls&quot;) %&gt;% 
  
  select(enddate, approve, disapprove) %&gt;% 
  
  #Calculating the rates
  mutate(
    net_approval_rate=approve-disapprove,
    
    #Finding Week No
    Week=isoweek(mdy(enddate)), 
    
    #use function to get the week in the year and arrange by weeks since elected
    WeekNo = Week-min(Week)) %&gt;%   
    arrange(WeekNo) %&gt;% 
  group_by(WeekNo) %&gt;% 
  
  #Calculating statistics
  summarize(mean_net_approval=mean(net_approval_rate),
            count = n(),
            sd1 = sd(net_approval_rate),
            t_critical = qt(0.975, count-1),
            se_rating = sd1/sqrt(count), 
            moe = t_critical*se_rating, 
            
            #Used to plot the SE on the graph
            y_min = mean_net_approval - moe, 
            y_max = mean_net_approval + moe) 
  
#plotting the data
ggplot(net_approval_polllist, aes(x = WeekNo, y = mean_net_approval)) + 

  #Adding the scatterplot
  geom_point(color =&quot;red&quot;) + 
  
  #Adding a trendline
  geom_smooth(se = F, method = &quot;loess&quot;) +
  
  #Standard error with the above calculations included
  geom_ribbon(aes(xmin = 0, xmax = Inf, ymin = y_min, ymax = y_max), alpha = 0.1, color = &quot;red&quot;) + 
  
  #Adding the path between the scatterplot
  geom_path(color =&quot;red&quot;) + 
  
  #Adding an orange line at 0 
  geom_hline(aes(yintercept=0.0,),linetype=1, color = &quot;Orange&quot;, size = 2) + 
  theme_classic()+
  scale_y_continuous(breaks=seq(-20,12,2))+
  theme(panel.grid.major.x=element_line(size=0.5),panel.grid.minor.y=element_line(size=0.5),panel.grid.major.y=element_line(size=0.5))+
  labs(title = &quot;Estimating Approval Margin (approve-disapprove) for Joe Biden&quot;,
       subtitle = &quot;Weekly average of polls&quot;,
       x = &quot;Weeks since election&quot;, 
       y = &quot;Average Approval Margin (Approve - Disapprove)&quot;)</code></pre>
<p><img src="/blogs2/blog2_files/figure-html/unnamed-chunk-4-1.png" width="648" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#  theme(panel.grid.minor = element_line(colour=&quot;blue&quot;, size=1.5))</code></pre>
<p>Interestingly, Bidens approval ratings have fallen steadily since his election.</p>
</div>
<div id="compare-confidence-intervals" class="section level2">
<h2>Compare Confidence Intervals</h2>
<p>Moreover the confidence interval has become wider likely because 1) the number of polls used for the SD calculation is larger and 2) polls are becoming more similar in their approval rate.</p>
</div>
</div>
<div id="challenge-1-excess-rentals-in-tfl-bike-sharing" class="section level1">
<h1>Challenge 1: Excess rentals in TfL bike sharing</h1>
<p>We first download the TfL data on how many bikes were hired every single day. We can get the latest data by running the following</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx&quot;

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp &lt;- tempfile(fileext = &quot;.xlsx&quot;)))</code></pre>
<pre><code>## Response [https://airdrive-secure.s3-eu-west-1.amazonaws.com/london/dataset/number-bicycle-hires/2021-09-23T12%3A52%3A20/tfl-daily-cycle-hires.xlsx?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJJDIMAIVZJDICKHA%2F20211014%2Feu-west-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20211014T133208Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=cb63a6012b9616a0354a7bc4d96e2096b39586a1e834b048e8e8c0f667139339&amp;X-Amz-SignedHeaders=host]
##   Date: 2021-10-14 13:32
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 174 kB
## &lt;ON DISK&gt;  C:\Users\karim\AppData\Local\Temp\Rtmp80o15U\file53f475081899.xlsx</code></pre>
<pre class="r"><code># Use read_excel to read it as dataframe
bike0 &lt;- read_excel(bike.temp,
                   sheet = &quot;Data&quot;,
                   range = cell_cols(&quot;A:B&quot;))

# change dates to get year, month, and week
bike &lt;- bike0 %&gt;% 
  clean_names() %&gt;% 
  rename (bikes_hired = number_of_bicycle_hires) %&gt;% 
  mutate (year = year(day),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))</code></pre>
<p>We can easily create a facet grid that plots bikes hired by month and year.</p>
<p><img src="C:/Users/karim/Desktop/Git/my_website/images/tfl_distributions_monthly.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Interestingly may and June have fallen a lot in bike rentals in 2020. This is likely because of less toursim due to COVID-19</p>
<p>We now want to reproduce some graphs from this data.</p>
<p>The first.</p>
<p><img src="C:/Users/karim/Desktop/Git/my_website/images/tfl_monthly.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Is reproduced through the following</p>
<pre class="r"><code>#Filtering data from 2016 and forward
bike_1 &lt;- bike %&gt;% 
  filter(year&gt;=2016) %&gt;% 
  group_by(year,month) %&gt;% 
  summarize(
    mean_bikehired=mean(bikes_hired)
  )

#filter for adding the blue line
bike_blue &lt;- bike %&gt;% 
  filter(year&gt;=2016 &amp; year&lt;=2019) %&gt;% 
  group_by(month) %&gt;% 
  summarize(
    mean_blue=mean(bikes_hired)
  )

#combine to a join dataset
bike_set &lt;- left_join(bike_1, bike_blue, by =&quot;month&quot;)

#Vector to be used for the axis tick marks
x_month &lt;- c(&quot;Jan&quot;,&quot;Feb&quot;,&quot;Mar&quot;,&quot;Apr&quot;,&quot;May&quot;,&quot;Jun&quot;,&quot;Jul&quot;,&quot;Aug&quot;,&quot;Sep&quot;,&quot;Oct&quot;,&quot;Nov&quot;,&quot;Dec&quot;)


#plot the data
ggplot(bike_set,aes(x=as.numeric(month)))+
  geom_line(aes(y=mean_bikehired),colour=&quot;black&quot;,size=0.1)+
  geom_line(aes(y=mean_blue),colour=&quot;blue&quot;,size=0.5)+
  facet_wrap(~year,nrow=2)+
  
  #This is used to calculate a ribbon that shades an area above and or below the mean
  geom_ribbon(aes(xmin = 0, xmax = Inf,ymin=mean_blue,ymax=mean_blue+ifelse(mean_bikehired&gt;mean_blue, mean_bikehired-mean_blue, 0),),fill=&quot;darkgreen&quot;,alpha=0.4)+
  geom_ribbon(aes(xmin = 0, xmax = Inf,ymax=mean_blue,ymin=mean_blue+ifelse(mean_bikehired&gt;mean_blue, 0,mean_bikehired-mean_blue)),fill=&quot;darkred&quot;,alpha=0.4) +
  
  
  labs(
    title = &quot;Monthly changes in TfL bike rentals&quot;, 
    subtitle = &quot;change from monthly average shown in blue and calculated between 2016-2019&quot;, caption= &quot;Source: TfL, London Data Store&quot;,
    x=&quot;&quot;, 
    y=&quot;Bike Rentals&quot;
  ) +
  theme_bw()+
  
  #Adding a scale for the months
  scale_x_continuous(breaks=c(1,2,3,4,5,6,7,8,9,10,11,12),labels=x_month)+  
  
  #Simplifying the theme
  theme(panel.border=element_blank(),
        panel.background = element_blank(),
        strip.background = element_rect(color=&quot;white&quot;,fill=&quot;white&quot;)  )+
  
  NULL</code></pre>
<p><img src="/blogs2/blog2_files/figure-html/unnamed-chunk-5-1.png" width="960" style="display: block; margin: auto;" />
Each year look similar in terms of bike rentals with especially 202 standing out as having low bike rentals in the early part of the year.</p>
<p>The second one looks at percentage changes from the expected level of weekly rentals. The two grey shaded rectangles correspond to Q2 (weeks 14-26) and Q4 (weeks 40-52).</p>
<p><img src="C:/Users/karim/Desktop/Git/my_website/images/tfl_weekly.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We produce this plot below</p>
<pre class="r"><code>#Calculating the bikes hired per week
bike_2 &lt;- bike %&gt;% 
  filter(year&gt;=2016) %&gt;% 
  group_by(year,month,week) %&gt;% 
  summarize(
    week_bikehired=mean(bikes_hired)
  ) %&gt;% 
  
  #We add a new year variable which says if it is January 1st but in week 53 the datapoint is then for the past year (i.e. a datapoint in 1st January but week 53 will be shown in the end of 2015 rather than the start of 2016)
  mutate(year_new = ifelse(week&gt;51 &amp; month == &quot;Jan&quot;, year-1, year)) %&gt;% 
  filter(year_new &gt; 2015)


#Setting up the weekly averages in 2016-2019
#filter for week bike rental 
bike_average &lt;- bike %&gt;% 
  filter(year&gt;=2016 &amp; year&lt;=2019) %&gt;% 
  group_by(week) %&gt;% 
  summarize(
    mean_2016_2019=mean(bikes_hired)
  )


#Joining the datasets
bike_week &lt;- left_join(bike_2, bike_average, by =&quot;week&quot;)

#Setting up the calculations to color the rug marks and pct changes. 
bike_week2 &lt;- bike_week %&gt;% 
  mutate(pct_change = week_bikehired/mean_2016_2019-1, 
         color_id = ifelse(pct_change&lt;0, 1, 0))


#Plotting the hart
ggplot(bike_week2, aes(x = week, y = pct_change)) + 
  geom_line(color = &quot;black&quot;, size = 0.2) + 
  
  #Ribbons which shade in green and red
  geom_ribbon(aes(xmin = 0, xmax = Inf,ymin=0,ymax=ifelse(pct_change&gt;0, pct_change, 0)),fill=&quot;green&quot;,alpha=0.4)+
  geom_ribbon(aes(xmin = 0, xmax = Inf,ymax=0,ymin=ifelse(pct_change&lt;0, pct_change, 0)),fill=&quot;red&quot;,alpha=0.4) +
  
  #Rug which colors based on a the variable computed above and on the x axis
  geom_rug(mapping = aes(color = factor(color_id)), sides = &quot;b&quot;) +
  
  #Setting the rug to green and red
  scale_color_manual(values = c(&quot;green&quot;, &quot;red&quot;)) +
  
  #By year
  facet_wrap(~year_new,nrow=2)+
  
  theme_bw() + 
  
  #Removing the legend
  guides(color=FALSE) + 
  
  #Scaling the axis and setting week numbers for the x axis
  scale_y_continuous(labels = scales::percent) + 
  scale_x_continuous(breaks = c(13,26,39,53)) + 
  
  #Simplifying the theme
  theme(panel.border=element_blank(),
        panel.background = element_blank(),
        strip.background = element_rect(color=&quot;white&quot;,fill=&quot;white&quot;), 
        axis.title.y = element_blank()) + 
  
  #Adding shading by week No
  annotate(&quot;rect&quot;, xmin=14, xmax=26, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;Grey&quot;) +
  annotate(&quot;rect&quot;, xmin=40, xmax=53, ymin=-Inf, ymax=Inf, alpha=0.2, fill=&quot;Grey&quot;) + 
  
  labs(title = &quot;Weekly changes in Tfl bike rentals&quot;, 
       subtitle = &quot;Change from weekly averages calculated between 2016-2019&quot;,
       x = &quot;Week&quot;) + 
  NULL </code></pre>
<p><img src="/blogs2/blog2_files/figure-html/unnamed-chunk-6-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We see a quite stable trend of bike rentals in the early years with some odd spikes later on.</p>
<p>Should you use the mean or the median to calculate your expected rentals? Why?</p>
<p>We believe we need to use median figures to account for outliers in data and look at the really expected number not affected by some extreme past numbers. The same logic appeals to finance markets - people tend to use median figures to form a forecasts consensus, fair multiple for a firm, or margin aim. This technique excludes all the extreme values because it accounts only for numbers in centre of sorted list. We want to use it here because we had extreme negative numbers in Q2 of 2020 due to COVID-19 outbreak and further during the sharp recovery of demand in H2 of 2020. Since we observe the graphs from 2016 to 2020 are normally distributed, we can also use the mean to calculate the expected rentals. However, we should be aware that by using the mean value, our calculated values can be easily affected by any extreme data point within the dataset.</p>
</div>
